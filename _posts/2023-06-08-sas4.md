---
title: 데이터 분석
date: 2023-06-08
categories: [통계]
tags: [보건의료빅데이터분석]
layout: post
---

#### 로지스틱 회귀 분석

- 종속변수가 질적자료인 경우 독립변수의 변화가 종속 변수의 값에 어떻게 영향을 미치는지를 알고자 할 때 사용

`오즈`

- 사건이 발생할 확률을 사건이 발생하지 않을 확률로 나눈 비율

- 오즈비가 1보다 작다는 것은 설명변수 x가 한 단위 증가하면 종속변수는 감소

| 구분 | 회귀분석 | 로지스틱 회귀분석 |
| --- | --- | --- |
| 모형적합성 | F검정 | 모형계수 전체테스트(Model chi-square test)Hosmer-Lemeshow's goodness of fit test |
| 모형평가 | R제곱 | Cox&Snell의 R제곱Nagelkerke의 R제곱 |
| 계수유의성 검정 | t | 우도비 검정(Likelihood ratio test) |
| 계수 | 베타 | (exp)베타 = 오즈비 |

- 로지스틱 회귀분석에서는 분류표에서 제시하는 분류의 정확도를 통해서도 모형의 적합성을 평가함

- 회귀분석에서는 x가 1증가할 때 y가 베타만큼 증가하거나 감소한다고 해석을 하는 반면, 로지스틱 회귀분석에서는 x가 1증가할 때 (exp)베타만큼 odds ratio(오즈비)가 증가했다고 해석

#### 데이터마이닝

- 대용량의 데이터로부터 자동 또는 반자동적인 방법을 통해 의미있는 `패턴, 규칙, 관계`를 찾음

- 소매 / 유통업 : 연관성 분석 알고리즘 사용

- 신용카드 회사 : 의사결정나무와 신경망 모형, 딥러닝 기법 등이 사용

- 제조업 : 연관성 분석과 군집분석 알고리즘을 사용

- 활용 분야 : DB 마케팅, 신용평가, 생물정보학, 텍스트 마이닝, 부정행위 적발 등

#### 기법

- 정형 데이터 분석 : 연관관계분석, 의사결정나무, 인공신경망 기법, 사례기반추론, 군집분석 기법

- 비정형 데이터 분석 : 웹문서, 소셜 데이터를 주로 분석하는 텍스트 마이닝, 웹 마이닝, 오피니언 마이닝, 소셜 네트워크 분석

- 데이터를 시각화해서 보여주는 데이터시각화 기법 등이 있음

#### 연관관계분석

- 연관 정도를 정향화 하기 위해 `지지도, 신뢰도, 향상도` 계산

- 품목 간의 어떠한 종속 관계가 존재하는지 찾아내는 작업

- 연관성 규칙을 통해 요소 간의 연관성 패턴 분석

- 분석을 통한 상품 추천이나 상품 진열 등에 사용

`활용 분야`

- 장바구니 분석, 크로스 마케팅, 카탈로그 디자인, 로스-리더, 군집분류

- 어떤 질병이 걸린 사람이 다음에 어떤 특정 질병이 합병증으로 발생할 확률이 높은가를 알아보는데 활용

> 
> 
> 
> #### 지지도 | Support
> 
> 
>
> - 전체 거래 중에서 어떠한 항목과 다른 항목 사이에 동시에 포함하는 거래의 빈도가 어느 정도인가를 나타냄  
> (조건과 결과 항목을 포함하는 거래 수) / (전체 거래 수)
> 
> 
> 
> #### 신뢰도 | Strength
> 
> 
>
> - 조건이 발생했을 때 결과가 동시에 일어난 확률
> - 신뢰도가 1에 가까울수록 의미있는 연관성을 가지고 있다고 할 수 있음
> - 연관성 규칙의 강도를 나타냄
> - (조건과 결과 항목을 포함하는 거래 수) / (조건 항목을 포함하는 거래 수)
> 
> 
> 
> #### 향상도 | Lift
> 
> 
>
> - 품목 X를 구매할 때 품목 Y도 구매하는지 서로 간의 연관성을 파악하는 비율
> - (연관성 규칙의 지지도) / (조건의 지지도)*(결과의 지지도)
> - `상호독립적 관계` : 상품 X와 Y의 Lift 값이 1인 경우
> - `양의 상관관계(보완재)` : 상품 X와 Y의 Lift값이 1보다 큰 경우
> - `음의 상관관계(대체제)` : 상품 X와 Y의 Lift값이 1보다 작은 경우
> 
> 

#### 의사결정나무

- 분류 및 예측에 주로 사용되는 기법

- 데이터를 분석하여 나온 결과물이 의사결정나무라는 그래프 형식으로 표현, 규칙 셋이라는 형식으로도 표현

`단계`

1. 의사결정나무의 형성
2. 가지치기
3. 타당성 평가
4. 해석 및 예측

`대표적 알고리즘`

- CART : 지니지수 또는 분산의 감소량을 분리기준으로 활용하고 이진분리를 수행

- C4.5 : 엔트로피지수를 분리 기준으로 활용(명목형 목표변수에 사용)

- CHAID : 카이제곱검정 또는 f점정을 분리 기준으로 활용하고 다지 분리 수행이 가능

`장점`

- 주요 변수의 선정이 용이 : 중요한 변수만 선별하여 의사결정나무를 구성

- 교호효과의 해석 : 두 개 이상의 변수가 결합하여 목표변수에 어떻게 영향을 주는지 쉽게 파악
교호작용 : 한 요인의 효과가 다른 요인의 수준에 의존하는 경우

비모수적 모형 : 선형성, 정규성, 등분산성 등의 가정이 필요 없음
해석의 용이성 : 모형의 이해가 쉽고, 새로운 자료의 모형에 적합하며, 어떤 입력변수가 목표변수를 설명하기에 좋은지 쉽게 파악 가능
지식의 추출 : 의사결정나무를 룰로 자동 변화가 가능하며, 이 룰은 다양한 활용이 가능

`단점`

- 비연속성 : 경계점 근방에서 예측 오류가 클 가능성이 있음

- 선형성 또는 주 효과의 결여

- 비안정성 : 새로운 자료의 예측에서는 불안정할 가능성이 높음

- 이진분리 이용 시 분리 가지의 수가 너무 많음

- 비용 증가

`활용 분야`

- 분류, 타겟 마케팅, 예측, 지식의 추출, 주요 변수의 추출

#### 인공신경망

- 데이터 안의 독특한 패턴이나 구조를 인지하는데 필요한 모델을 구축하는 기법

- 간단한 계산능력을 가진 처리 단위, `뉴런 또는 노드`들이 서로 복잡하게 연결된 컴퓨터 시스템으로서 외부에서 주어진 입력에 대해 반응

- 노드는 신경망모형에서 가장 기본적인 요소, 가중치를 통해서 의사결정

- 자료의 관련성을 나타내 줄 수 있는 기법으로 예측을 최대화하기 위한 조직화를 찾기 위해 반복적으로 학습하는 원리 이용

`장점`

- 회귀분석과 같은 선형기법과 비교하여 비선형기법으로서의 예측력이 뛰어남

- 자료에 대한 통계적 분석 없이 결정을 수행할 수 있음

- 통계적 기본가정이 적고 유연하여 다양하게 활용

- 데이터 사이즈가 작은 경우, 불완전 데이터, 노이즈 데이터가 많은 경우 인공신경망 모델의 성능이 일반적으로 다른 기법과 비교해 우수

`단점`

- 모델이 제시하는 결과에 대해서 왜 그런 결과가 나오는지에 대한 원인을 명쾌하게 설명할 수 없음

- 모델의 학습에 시간이 과도하게 많이 소요

- 전체적인 관점에서의 최적해가 아닌 지역 내 최적해가 선택될 수 있음

- 과적합화가 될 수 있음

`활용분야`

- 마케팅, 회계, 재무, 인사관리, 생산관리

#### 사례기반추론

- 과거에 있었던 사례들의 결과를 바탕으로 새로운 사례의 결과를 예측하는 기법

- 과거에 발생한 문제는 미래에 다시 비슷한 형태의 문제로 발생할 가능성이 높고 새로운 문제를 해결할 수 있는 정답이 과거의 문제를 해결했던 정답과 유사할 것이라는 가정을 이용

- 과거 사례들을 저장해 둔 사례기반으로부터 해결하고자 하는 새로운 사례와 가장 유사한 사례를 검색한 후, 유사 사례의 해결책을 바탕으로 당면한 문제의 해결책을 제안하는 과정으로 진행

- 사례기반추론을 이용하기 위해서는 일반적으로 과거의 사례와 사례들 사이의 유사 정도를 측정하기 위한 유사도 척도를 준비
  - 유사도 측정 도구는 여러가지 방법이 제안되고 있지만 일반적으로 근접이웃 방법론이 가장 많이 이용됨

- 근접이웃방법론으로 입력문제 T와 사례 S에 대한 유사도를 계산
  - 근접이웃방법론을 이용한 유사도 계산방법
  - T는 입력문제, S는 학습된 사례, Wi는 T와 S의 각 속성에 대한 가중치로 정의

- 근접이웃방법론으로 입력문제 T와 사례 S에 대한 유사도를 계산
  - 근접이웃방법론을 이유한 유사도 계산방법
  - 각 속성에 대한 유사도 함수 f는 자료가 수치형 자료인지 또는 범주형 자료인가에 따라서 계산
  - 수치형 속성인 경우 함수 f 계산 : f =1 – I (비교사례의 속성값-과거사례의 속성값) / 해당속성의 최대값 I
  - 범주형 속성인 경우 함수 f 계산 : f = 1 – I 비교사례의 속성값 F – 과거사례의 속성값 I M

`과정`
1. 검색 : 대상 문제가 주어지면, 사례 DB에서 그것을 풀기에 적절한 사례들을 검색
2. 재사용 : 이전의 사례로부터 대상문제의 해결 방법을 연결
3. 수정 : 이전의 해결방법을 대상의 상황에 연결시킨 후, 그 새로운 해결방법을 실 세계에서 테스트하고 필요하다면 수정
4. 유지 : 해법이 성공적으로 대상 문제에 적용된 후에, 그러한 새로운 경험이 사례 DB에 새로운 사례로서 저장

`장점`

- 인간의 문제 해결 방식과 유사하기 때문에 그 결과를 이해하기 쉬움

- 새로운 사례를 단순히 저장하는 것만으로도 추가적인 작업 없이 학습 진행

- 사례기반추론 모델은 구조가 간단하고 이해가 용이

- 수치형 변수와 범주형 변수 모두 사용 가능

- 복잡한 문제를 비교적 적은 정보로 의사결정, 문제해결 가능

`단점`

- 전통적인 사례기반추론의 경우, 타 인공지능기법 또는 데이터마이닝 기법에 비해 정확도가 상대적으로 크게 떨어짐

- 사례를 저장하기 위한 공간이 많이 필요

- 일반화를 위한 학습과정과 해결이 동시에 일어나기 때문에 많은 시간이 소요

- 사례를 설명하고 있는 속성이 적절하지 못한 경우 성능이 크게 저하

`활용 분야`

- 고객 응대, 진단 시스템, 전문가 시스템, 프로젝트 관리, 지식관리 시스템

#### 군집분석

- 전체 데이터를 군집을 통해 잘 구분하는 것으로 다양한 특징을 가진 관찰 대상으로부터 동일집단으로 분류하는데 사용

- 유사한 특성을 가진 개체를 합쳐가면서 최종적으로 `유사 특성의 군집을 찾아내는 분류방법`

- N개 개체들 사이의 유사성 또는 비유사성의 정도를 측정하여 개체들을 가까운 순서대로 군집화하는 통계적 분석방법

- 구분하려고 하는 각 군집에 대한 아무런 사전지식이 없는 상태에서 분류하는 것
  - `무감독학습(Unsupervised Learning)`에 해당
  - 개체들에 대한 사전지식 없이 유사도에 근거하여 군집들을 구분
  - `군집(cluster)` : 개체 공간에 주어진 유한개의 개체들이 서로 가깝게 모여서 무리를 이루고 있는 개체 집합
  - `클러스터링(clustering)` : 개체 집합을 군집화하는 과정

- 군집분석에서의 군집 특성
  - `군집간의 유사도를 평가하기 위해서 여러 가지의 거리측정함수 사용`
  - 유클리드 거리, 유클리디안 제곱거리, 민코우스키 거리, 맨하튼 거리 등이 사용

`계층적 군집(Hierachical cluster analysis)`

- 유사성이 `가까운 순서대로 개체들을 묶어` (군집화)하는 방법

- 개별대상 간의 거리에 의하여 가장 가까이에 있는 대상자들로부터 시작하여 결합

- 한 대상이 일단 어느 군집에 소속되면 다른 군집으로 이동될 수 없으며, `이상개체(outlier)는 제거되지 않고 반드시 어느 군집에 속함`

- 계층적 군집분석은 군집간의 거리와 유사성을 정하는 방법에 따라 단일연결방식, 완전연결방식, 평균연결방식, Ward 연결법 등으로 구분함

`거리측정함수`

- 유클리드 거리(Euclidean distance) : 변수값의 차이를 제곱하여 합산한 거리, 다차원공간에 직선 최단 거리를 의미함

- `유클리디안 제곱거리(Squared Euclidean distance)` : 유클리디안 거리를 제곱한 거리

- 맨하튼 거리(Manhattan distance) : 변수값들의 차이를 절대화하여 합한 거리, 이상치 비중 약해짐

- 민코우스키 거리(Minkowski distance) : 거리를 산정하는 일반식으로 함수에 포함된 지수들을 조정함으로써 다양한 방법의 거리를 구할 수 있음

`비계층적 군집분석`

- 군집의 수가 한 개씩 감소하는 것이 아니라 사전에 정해진 군집의 숫자에 따라 대상들이 군집들에 할당되는 것

- 군집의 중심이 되는 (seed 점)을 선택하여 그 seed 점과 유사성이 높은(거리가 가까운) 개체들을 그룹화 하는 방법

- 많은 데이터를 빠르고 쉽게 분류할 수 있으나 군집의 수를 미리 정해주어야 하고, 군집을 형성하기 위한 초기값에 따라 군집결과가 달라짐

`K-평균(비계층적) 군집분석`

- K개 군집에 1개씩의 개체를 심고 모든 개체를 가장 가까운 군집 중심을 찾아 배속시키고 새로운 군집중심을 계산하여 변화가 없을 때까지 반복하여 군집화

> 
> 
> 
> #### 단계1
> 
> 
>
> - 개체를 초기의 K개 군집으로 분류한다. 이런 군집의 초기 분류는 분석자가 지정할 수도 있고, 프로그램에서 제공할 수도 있다.
> 
> 
> 
> #### 단계2
> 
> 
>
> - 각 군집의 각각의 변수에 대해서 중심점들을 계산한다.
> 
> 
> 
> #### 단계3
> 
> 
>
> - 각 케이스에 대해 중심점과의 거리를 계산하는데 현재 속한 군집의 중심점과 가까우면 그대로 두고 그렇지 않으면 군집을 변경한다.
> 
> 
> 
> #### 단계4
> 
> 
>
> - 어떤 케이스도 다른 군집에 재배정되지 않을 때까지 반복한다.
> 
> 

#### 비정형 데이터마이닝

- 정형화되지 않은 데이터

- 미리 정의된 데이터 모델(구조)를 가지고 있지 않은 데이터(문서, 영상, 음성 등)

- 비정형 데이터의 유형은 크게 텍스트, 이미지, 음성과 영상, 로그 파일로 구분

- 비정형 데이터는 불규칙 정도에 따라 반정형 데이터로 구분
  - 반정형 데이터는 관계형 데이터베이스나 다른 형태의 데이터 테이블로 조직된 데이터 모델의 정형적 구조를 따르지 않지만, 어의적 요소를 분리시키고 데이터 내의 레코드와 필드의 계층 구조가 있게 하는 태그(Tag)나 마커(Marker)를 포함하는 정형 데이터

- `반정형 데이터는 같은 클래스에 속하는 속성들을 순서에 상관없이 서로 묶을 수 있고 다른 속성들을 포함시킬 수도 있음`

- 최근 객체지향 데이터베이스에서 반정형 데이터가 많이 등장

- 마크업(Markup) 언어, 이메일, EDI(Electronic Data Interchange) 등

- `객체지향 데이터베이스(ODB: Object-oriented Database)`
  - 객체지향 데이터베이스는 객체지향 데이터 모델의 개념을 반영하여 실세계에 존재하는 객체를 표현하고 관리하는 데이터베이스 기술
  - (예: 객체는 사람, 학생, 교수 등 실세계의 개체를 추상적으로 표현한 것. 객체가 학생일 경우 객체 식별자는 학생을 유일하게 식별하기 위해 시스템에 의해 생성된 값을 의미함)

- XML(eXtensible Markup Language)
  - 데이터 구조와 데이터를 스스로 기술하는 수단을 가진 비교적 최근에 나온 마크업 언어
  - 이전에는 기능적 수준에서 구조적 엄격함이 못 미치는 인상을 가지게 하여 비정형형태로 보았으나, 실제로는 아주 엄격한 요소구조와 데이터 형식과 인간 중심 흐름 및 계층구조를 가능하게 하는 ‘유연성 있는 구조’로 언급될 수도 있음

`비정형 데이터 분석과 마이닝`

- 빅데이터 환경에서 거의 80% 이상이 비정형 데이터이므로, 빅데이터의 데이터 마이닝은 비정형 데이터 마이닝에 초점

- 통계 기반의 데이터 분석도구 사용

- OLAP 분석을 통해 다양한 관점으로 조명하여 의미있게 해석

- 데이터 사이에 숨겨진 관계, 패턴, 경향 등을 추출

- 비정형 데이터의 내용 파악과 비정형 데이터 속 패턴(Pattern) 발견을 위해 데이터 마이닝, 텍스트 분석, 비표준 텍스트 분석 등과 같은 다양한 기법을 사용

- 비정형 데이터를 정련 과정을 통해 정형데이터로 만든 후, 분류, 군집화, 회귀분석, 요약, 이상감지 분석 등의 데이터 마이닝을 통해 의미 있는 정보를 발굴

- 텍스트를 정형화하는 방법

- 주요단어 등의 추출 등 정제과정을 거쳐 정형화된 데이터 구조로 변환하는 것이 가장 일반적인 방법

- 메타데이터(Meta Data)로 직접 태그(Tag)

- 고도의 텍스트 마이닝 기반 정형화를 위해 텍스트속 단어와 스피치(Speech)의 한 부분이 대응되게 태그

- 정제된 데이터베이스를 기반으로 일정한 기준이 적용된 상식적 범위에서 부분적인 데이터를 다루는 정형 데이터 마이닝의 한계를 뛰어넘는 기법 존재
  - 텍스트 마이닝, 웹 마이닝, 오피니언 마이닝, 소셜 마이닝

`텍스트 마이닝`

- 인간의 언어로 이루어진 비정형 텍스트 데이터들을 자연어 처리(Natural Language Processing)방식을 이용하여 대규모 문서에서 정보 추출, 연계성 파악, 분류 및 군집화, 요약 등을 통해 데이터에 숨겨진 의미를 발견하는 기법

- 기존 통계분석이나 데이터마이닝을 적용하기에 부적합한 데이터를 다룸

- 텍스트 데이터 마이닝(Text Data Mining), 텍스트 분석(Text Analytics), 텍스트 데이터베이스로부터 지식발견(Knowledge Discovery in Textual Database), 오피니언문서 마이닝(Document Mining) 등으로 호칭

- 텍스트 마이닝은 대규모의 텍스트에서 고품질 정보를 도출, 고품질 정보는 통계적인 패턴학습 등의 수단을 통해 패턴과 추세를 파악함으로써 도출

- 텍스트 마이닝은 일반적으로 입력 텍스트를 정형화한 다음, 정형화 데이터 내에서 패턴을 추출하고 난 후, 출력을 평가하고 번역하는 과정을 포함

- 정형화는 입력 텍스트를 파싱(Parsing)할 때 추출되는 언어적 특징은 추가시키고 그 이외의 것들은 제거하면서 데이터베이스와 같은 정형화된 구조 속에 삽입하는 것

- 그리고 고품질 정보는 보통 새롭고 적절하며 관심을 끄는 데이터들의 집합으로서 어떤 목적과 관련하여 의미 있는 정보

- 텍스트 데이터마이닝 텍스트 분석
  - 정보검색, 단어 빈도 분포를 연구하는 어휘분석, 패턴인식, 태그 및 주석, 정보추출, 링크 및 연결분석을 내포하는 데이터마이닝, 시각화, 예측 분석 등이 필요

- 정보 검색 기법, 자연어 처리 기법(의사소통 언어처리기법, 구어처리기법), 특징 추출 기법, 텍스트 범주화 기법, 군집화 기법, 연결분석 등의 기법 존재

- 여러 가지 종류의 텍스트 데이터로부터 지식을 발견하는 과정

- 텍스트 마이닝의 목적은 비정형 데이터나 정형 데이터, 반정형 데이터를 처리하여 의사결정을 위해 필요한 고차원적이고 의미 있는 정보나 지식을 추출하는 것

> 
> 
> 
> #### 입력 -> 처리(준비 -> 전처리 -> 지식추출) -> 출력
> 
> 
>
> - 준비 : 입력되는 여러 가지 텍스트 문서의 데이터들을 문제 범위에 적절한 것으로
> 확립
> - 전처리 : 조직화된 텍스트들을 정형화된 표현 양식으로 만듦
> - 지식 추출 :
>   - 정형데이터에서 의미 있는 패턴이나 관계와 같은 지식 발견
>   - 분류, 클러스터링, 개념 및 개체 추출, 세분화된 분류 체계의 생산, 심리 분석, 문서 요약, 개체 관계 모델링
> 
> 
> 

`오피니언 마이닝`

- 어떤 사안이나 인물, 이슈, 이벤트 등과 관련 원천 데이터에서 `의견이나 평가, 태도, 감정등과 같은 주관적인 정보를 식별하고 추출하는 것`

- 오피니언 분석, 평판 분석, 정서 분석

- 오피니언 분석의 기본적인 작업

- 문서, 문장, 특징, 관점 수준에서 표현된 견해가 긍정적인지, 부정적인지, 중립적인지, 진보적인지 주어진 텍스트의 특성을 분류하는 것

- 온라인 쇼핑몰에서 잠재 구매자의 상품평 검색효율을 높이기 위해 상품평 데이터에 순위를 결정하는데 이용

- 영화 관람 후기 요악, 긍정/부정 평가

- 법률 분야의 블로그를 대상으로 고객의 반응이나 법률적 이슈에 대한 모니터링

- 소셜 미디어 오피니언들을 조기 감지하여 기업의 위기 상황을 인지하고 위기에 대응할수 있는 위기관리 모델의 핵심 정보 활용

- 오피니언을 경제적 관점에서 정량화하여 금액으로 환산

- SNS에서 실시간으로 핫 토필을 추출하고 오피니언의 흐름을 분석하여 이벤트, 마케팅, 트렌드 분석 등 다양한 활용

- 트위터에서 감지되는 시장 분위기를 이용하여 주가의 흐름 예측

`오피니언 마이닝 유의점`

- 여론 추정의 근거가 되는 감성사전의 구축을 소홀히 하지 말 것

- 단어의 맥락을 잘못 파악할 우려가 있음 : 특정 단어는 맥락에 따라 긍정과 부정이 반어적으로 사용될 수 있음

`웹 마이닝`

- 데이터마이닝 기술의 응용분야로서 인터넷을 통해 웹 서비스를 이용하면서 웹에서 패턴을 발견하는 것

- 데이터의 속성이 반정형이거나 비정형이고, 링크(Link) 구조를 가지고 있기 때문에 전통적인 데이터마이닝 기술에 추가적인 분석기법이 필요

- 웹 콘텐츠 마이닝 : 웹 페이지에서 유용한 데이터, 정보, 지식을 마이닝하고 추출하고 통합하는 것

- 웹 사용 마이닝 : 웹 사이의 연결 분석, 웹 사이트의 노드와 연결 구조를 분석하기 위해 그래프 이론을 사용하는 과정

- 분류 : 웹 구조 마이닝, 웹 콘텐츠 마이닝, 웹 사용 마이닝

> 
> 
> 
> #### 웹 구조 마이닝
> 
> 
>
> - 웹사이트의 노드와 연결구조를 분석하는 기법
> - 하이퍼링크로부터 패턴을 찾아내거나 웹페이지 구조를 분석
> - 하이퍼링크 : 웹페이지가 연결된 구조
> 
> 
> 
> #### 웹 사용 마이닝
> 
> 
>
> - 웹서버 로그 파일을 분석하여 웹 사이트 개선이나 고객 특성을 반영한 맞춤형 서비스를 지향
> - 웹 서버 로그 파일 : 인터넷 이용자의 이용 경로
> 
> 
> 
> #### 웹 콘텐츠 마이닝
> 
> 
>
> - 웹 페이지에 저장된 콘텐츠로부터 웹 사용자가 원하는 정보를 빠르게 찾는 기법
> - 검색엔진에 사용(웹 페이지를 다루고 있는 주제에 따라 자동적으로 분류)
> 
> 

`소셜 데이터 마이닝`

- 국외
  - 사용자의 로그, 관심사, 정보를 분석하여 트렌드 감지
  - 브랜드를 모니터링, 감성분석, 마케팅 등을 제공할 수 있는 기반환경 서비스
  - 구글은 구글 트렌드를 통해 실시간 핫이슈 검색, 실시간 순위 및 순위차트 제공, 카테고리별 이슈 분류, 기간별 설정 및 검색 기능을 제공

- 국내
  - 소셜 미디어 분석에서 언어 분석 기술을 적용해 검색어에 대한 기간별 소셜 모니터링, 연관어 탐색, 감성 분석 서비스 등을 제공
  - 다음소프트의 경우 소셜 매트릭스 서비스 제공

- 개인의 일상 정보가 연결된 사회적 관계망을 분석하는 것이 필요한데 그것이 소셜 네트워크 애널리틱스(Social Network Analytics:SNA)임
- 노드와 링크로 구성되는 네트워크 이론에 의해 사회적 관계(우정, 연대감, 조직력, 성향)를 보여주는 것

- 소셜 네트워크 연결구조 및 연결강도 등을 바탕으로 노드의 복잡도를 측정하여, 소셜 네트워크 상에서 연결의 중심 역할을 하는 영향력이 있는 행위자를 파악

- 파악하고 관리하는 것이 마케팅 관점에서 매우 중요

- 보험사기인지시스템(IFAS)
  - 소셜 네트워크 분석(SNA) 기법을 활용해 보험설계사와 피보험자, 병원과의 관계를 분석하고 보험사기 혐의가 짙은 패턴을 가려내는 시스템
  - IFAS상의 보험계약 및 보험금 지급 데이터를 활용하여 계약자, 설계사, 병원 등 개별혐의자들 간의 상호연관성을 분석하고, 보험사기 혐의 그룹을 시스템적으로 추출하는 기법
  - IFAS는 SNA 기법을 통해 보험사기 혐의 가능성을 계량화하여 보험설계사와 병원을 혐의그룹 형태로 분류, 그 연계도 (혐의그룹 모델)를 추출하고, 선정된 혐의 그룹 모델에 대해 시각화하고 그 특성 분석

#### 데이터 시각화

- 러셀(Russell Ackoff, 1989)의 연구 : 데이터를 지식화하기 위한 과정이 시각화

- 데이터 분석 결과를 사용자가 쉽게 이해할 수 있도록 시각적 수단을 통해 제시하는 것

- `시각화란 같은 범주 안에서 많은 양의 데이터에 의미를 부여함으로써 공간에 배치된 숫자의 패턴을 인지하게 만든 것`

- 다른 학문과 융합하여 다양한 정보 전달이나 상황 분석을 위한 시각적 도구로 메시지 전달을 위한 시각적 표현으로 많이 사용됨

`특성`

- 인간의 정보 처리 능력을 확장시켜 `정보를 직관적으로 이해`

- `많은 데이터를 동시에 차별적으로 제시`

- 다른 방식으로 어려운 지각적 추론 가능

- 흥미를 유발하고, 주목성이 높아지며 인간의 경험을 풍부하게 함

- 문자보다 친근하게 정보 전달, 다양한 계층 사람들에게 쉽게 접근

- 데이터 간 관계, 차이를 명확히 드러내며, 이면의 의미, 뜻, 이야기 (narrative)를 만듦

- 데이터를 입체적, 거시적/미시적 표현이 가능하고 위계를 부여

`원리`

- 각각의 음식은 고유한 맛과 향이 있다. => `하나의 시각화는 그 데이터셋에 표현하는 유일한 특성`들만을 표현

- 확실한 일품요리를 차려라! => 가능한 한 소중한 정보만으로 최소화

- 손님이 원하는 식사를 제공하라 => 청중이 누구이며, 시각화에 접근하는 이들의 최종 목적은 무엇인가?

`단계`
1. 획득 : 데이터 획득
2. 구조화 : 데이터 구조화 및 분류
3. 추출 : 관심 데이터 추출
4. 마이닝 : 통계적인 방법 또는 데이터마이닝 기법 적용
5. 시각화 : 바 그래프, 리스트 또는 트리 등의 기본적 시각 모델 선택
6. 재정의 : 보다 명확하게, 매력적 표현으로 개선
7. 상호작용 : 데이터 변경 또는 보여지는 특징을 조작하는 방법 추가

`데이터 형식`

- 단변수 데이터, 이변수 데이터(산점도), 삼변수 데이터(산점도 매트릭스), 다변수 데이터(좌표플롯)

`데이터 표현 특성`

- 크기, 색상, 위치, 네트워크, 시간, 다중표현기법

`인코딩 형식`

- 선 : 두가지 실체를 가장 간단하게 제시할 수 있는 방법

- 지도&다이어그램 : 벤다이어그램, 인포크리스탈, 클러스터맵

- 트리표시 : 노드와 링크 형태의 관계에 적용되며, 콘트리, 하이퍼볼릭 브라우저, 수형도 등으로 표현

`빅데이터 시각화 기술`

- 시간 시각화, 분포 시각화, 관계 시각화, 비교 시각화, 인포그래픽스